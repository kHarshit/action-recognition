{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kHarshit/action-recognition/blob/main/pyslowfast_kinetics400.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee518b08",
      "metadata": {
        "id": "ee518b08"
      },
      "source": [
        "# SlowFast\n",
        "\n",
        "Using **SlowFast networks pretrained on the Kinetics 400 dataset**\n",
        "\n",
        "\n",
        "Load the model:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "!pip install av"
      ],
      "metadata": {
        "id": "4NSGaC-q8hFS"
      },
      "id": "4NSGaC-q8hFS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Choose the `slowfast_r50` model\n",
        "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvkcHqhKd1CY",
        "outputId": "16c64323-eb28-45de-efd6-2a0f1b12ae35"
      },
      "id": "xvkcHqhKd1CY",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_pytorchvideo_main\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOWFAST_8x8_R50.pyth\" to /root/.cache/torch/hub/checkpoints/SLOWFAST_8x8_R50.pyth\n",
            "100%|██████████| 264M/264M [00:02<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import json\n",
        "import urllib\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ")\n",
        "\n",
        "import urllib.request\n",
        "import json"
      ],
      "metadata": {
        "id": "ksYLJWCNFR0c"
      },
      "id": "ksYLJWCNFR0c",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "975ad310",
      "metadata": {
        "id": "975ad310"
      },
      "source": [
        "#### Setup\n",
        "\n",
        "Set the model to eval mode and move to desired device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "944476fc",
      "metadata": {
        "attributes": {
          "classes": [
            "python "
          ],
          "id": ""
        },
        "id": "944476fc"
      },
      "outputs": [],
      "source": [
        "# Set to GPU or CPU\n",
        "device = \"cuda\"\n",
        "model = model.eval()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a4904b",
      "metadata": {
        "id": "a0a4904b"
      },
      "source": [
        "Download the id to label mapping for the Kinetics 400 dataset on which the torch hub models were trained. This will be used to get the category label names from the predicted class ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "339ded75",
      "metadata": {
        "id": "339ded75"
      },
      "outputs": [],
      "source": [
        "json_url = \"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\"\n",
        "json_filename = \"kinetics_classnames.json\"\n",
        "try: urllib.URLopener().retrieve(json_url, json_filename)\n",
        "except: urllib.request.urlretrieve(json_url, json_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ff9dc0e6",
      "metadata": {
        "id": "ff9dc0e6"
      },
      "outputs": [],
      "source": [
        "with open(json_filename, \"r\") as f:\n",
        "    kinetics_classnames = json.load(f)\n",
        "\n",
        "# Create an id to label name mapping\n",
        "kinetics_id_to_classname = {}\n",
        "for k, v in kinetics_classnames.items():\n",
        "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kinetics_id_to_classname"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHJUk_UWcHhR",
        "outputId": "7e45a7db-0950-4391-9b54-5eecef6c5606"
      },
      "id": "nHJUk_UWcHhR",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{290: 'sharpening knives',\n",
              " 115: 'eating ice cream',\n",
              " 81: 'cutting nails',\n",
              " 53: 'changing wheel',\n",
              " 19: 'bench pressing',\n",
              " 88: 'deadlifting',\n",
              " 111: 'eating carrots',\n",
              " 192: 'marching',\n",
              " 358: 'throwing discus',\n",
              " 231: 'playing flute',\n",
              " 72: 'cooking on campfire',\n",
              " 33: 'breading or breadcrumbing',\n",
              " 218: 'playing badminton',\n",
              " 276: 'ripping paper',\n",
              " 244: 'playing saxophone',\n",
              " 197: 'milking cow',\n",
              " 169: 'juggling balls',\n",
              " 130: 'flying kite',\n",
              " 43: 'capoeira',\n",
              " 187: 'making jewelry',\n",
              " 100: 'drinking',\n",
              " 228: 'playing cymbals',\n",
              " 61: 'cleaning gutters',\n",
              " 161: 'hurling (sport)',\n",
              " 239: 'playing organ',\n",
              " 361: 'tossing coin',\n",
              " 395: 'wrestling',\n",
              " 103: 'driving car',\n",
              " 150: 'headbutting',\n",
              " 147: 'gymnastics tumbling',\n",
              " 186: 'making bed',\n",
              " 0: 'abseiling',\n",
              " 155: 'holding snake',\n",
              " 278: 'rock climbing',\n",
              " 71: 'cooking egg',\n",
              " 182: 'long jump',\n",
              " 17: 'bee keeping',\n",
              " 365: 'trimming or shaving beard',\n",
              " 63: 'cleaning shoes',\n",
              " 86: 'dancing gangnam style',\n",
              " 50: 'catching or throwing softball',\n",
              " 164: 'ice skating',\n",
              " 168: 'jogging',\n",
              " 116: 'eating spaghetti',\n",
              " 28: 'bobsledding',\n",
              " 8: 'assembling computer',\n",
              " 227: 'playing cricket',\n",
              " 238: 'playing monopoly',\n",
              " 143: 'golf putting',\n",
              " 188: 'making pizza',\n",
              " 166: 'javelin throw',\n",
              " 211: 'peeling potatoes',\n",
              " 57: 'clapping',\n",
              " 36: 'brushing hair',\n",
              " 129: 'flipping pancake',\n",
              " 101: 'drinking beer',\n",
              " 99: 'dribbling basketball',\n",
              " 219: 'playing bagpipes',\n",
              " 325: 'somersaulting',\n",
              " 42: 'canoeing or kayaking',\n",
              " 275: 'riding unicycle',\n",
              " 355: 'texting',\n",
              " 352: 'tasting beer',\n",
              " 154: 'hockey stop',\n",
              " 225: 'playing clarinet',\n",
              " 389: 'waxing legs',\n",
              " 80: 'curling hair',\n",
              " 281: 'running on treadmill',\n",
              " 346: 'tai chi',\n",
              " 104: 'driving tractor',\n",
              " 293: 'shaving legs',\n",
              " 291: 'sharpening pencil',\n",
              " 190: 'making sushi',\n",
              " 327: 'spray painting',\n",
              " 305: 'situp',\n",
              " 237: 'playing kickball',\n",
              " 331: 'sticking tongue out',\n",
              " 149: 'headbanging',\n",
              " 132: 'folding napkins',\n",
              " 241: 'playing piano',\n",
              " 312: 'skydiving',\n",
              " 85: 'dancing charleston',\n",
              " 163: 'ice fishing',\n",
              " 359: 'tickling',\n",
              " 13: 'bandaging',\n",
              " 151: 'high jump',\n",
              " 185: 'making a sandwich',\n",
              " 271: 'riding mountain bike',\n",
              " 82: 'cutting pineapple',\n",
              " 125: 'feeding goats',\n",
              " 87: 'dancing macarena',\n",
              " 220: 'playing basketball',\n",
              " 179: 'krumping',\n",
              " 152: 'high kick',\n",
              " 12: 'balloon blowing',\n",
              " 217: 'playing accordion',\n",
              " 224: 'playing chess',\n",
              " 159: 'hula hooping',\n",
              " 263: 'pushing wheelchair',\n",
              " 268: 'riding camel',\n",
              " 27: 'blowing out candles',\n",
              " 121: 'extinguishing fire',\n",
              " 373: 'using computer',\n",
              " 173: 'jumpstyle dancing',\n",
              " 397: 'yawning',\n",
              " 396: 'writing',\n",
              " 172: 'jumping into pool',\n",
              " 96: 'doing laundry',\n",
              " 118: 'egg hunting',\n",
              " 284: 'sanding floor',\n",
              " 200: 'moving furniture',\n",
              " 119: 'exercising arm',\n",
              " 345: 'sword fighting',\n",
              " 303: 'sign language interpreting',\n",
              " 74: 'counting money',\n",
              " 15: 'bartending',\n",
              " 65: 'cleaning windows',\n",
              " 23: 'blasting sand',\n",
              " 213: 'petting cat',\n",
              " 320: 'sniffing',\n",
              " 31: 'bowling',\n",
              " 242: 'playing poker',\n",
              " 347: 'taking a shower',\n",
              " 382: 'washing hands',\n",
              " 384: 'water sliding',\n",
              " 254: 'presenting weather forecast',\n",
              " 360: 'tobogganing',\n",
              " 51: 'celebrating',\n",
              " 138: 'getting a haircut',\n",
              " 321: 'snorkeling',\n",
              " 390: 'weaving basket',\n",
              " 245: 'playing squash or racquetball',\n",
              " 206: 'parasailing',\n",
              " 202: 'news anchoring',\n",
              " 18: 'belly dancing',\n",
              " 393: 'windsurfing',\n",
              " 32: 'braiding hair',\n",
              " 78: 'crossing river',\n",
              " 181: 'laying bricks',\n",
              " 280: 'roller skating',\n",
              " 156: 'hopscotch',\n",
              " 248: 'playing trumpet',\n",
              " 108: 'dying hair',\n",
              " 366: 'trimming trees',\n",
              " 256: 'pumping fist',\n",
              " 236: 'playing keyboard',\n",
              " 322: 'snowboarding',\n",
              " 136: 'garbage collecting',\n",
              " 226: 'playing controller',\n",
              " 94: 'dodgeball',\n",
              " 266: 'recording music',\n",
              " 75: 'country line dancing',\n",
              " 84: 'dancing ballet',\n",
              " 137: 'gargling',\n",
              " 165: 'ironing',\n",
              " 260: 'push up',\n",
              " 135: 'frying vegetables',\n",
              " 307: 'ski jumping',\n",
              " 201: 'mowing lawn',\n",
              " 139: 'getting a tattoo',\n",
              " 279: 'rock scissors paper',\n",
              " 55: 'cheerleading',\n",
              " 374: 'using remote controller (not gaming)',\n",
              " 289: 'shaking head',\n",
              " 282: 'sailing',\n",
              " 363: 'training dog',\n",
              " 160: 'hurdling',\n",
              " 128: 'fixing hair',\n",
              " 67: 'climbing ladder',\n",
              " 126: 'filling eyebrows',\n",
              " 329: 'springboard diving',\n",
              " 117: 'eating watermelon',\n",
              " 106: 'drumming fingers',\n",
              " 386: 'waxing back',\n",
              " 229: 'playing didgeridoo',\n",
              " 339: 'swimming backstroke',\n",
              " 22: 'biking through snow',\n",
              " 380: 'washing feet',\n",
              " 198: 'mopping floor',\n",
              " 357: 'throwing ball',\n",
              " 113: 'eating doughnuts',\n",
              " 102: 'drinking shots',\n",
              " 368: 'tying bow tie',\n",
              " 91: 'dining',\n",
              " 337: 'surfing water',\n",
              " 338: 'sweeping floor',\n",
              " 145: 'grooming dog',\n",
              " 47: 'catching fish',\n",
              " 257: 'pumping gas',\n",
              " 273: 'riding or walking with horse',\n",
              " 196: \"massaging person's head\",\n",
              " 5: 'archery',\n",
              " 162: 'ice climbing',\n",
              " 243: 'playing recorder',\n",
              " 89: 'decorating the christmas tree',\n",
              " 210: 'peeling apples',\n",
              " 324: 'snowmobiling',\n",
              " 249: 'playing ukulele',\n",
              " 109: 'eating burger',\n",
              " 38: 'building cabinet',\n",
              " 332: 'stomping grapes',\n",
              " 105: 'drop kicking',\n",
              " 209: 'passing American football (not in game)',\n",
              " 3: 'applauding',\n",
              " 158: 'hugging',\n",
              " 114: 'eating hotdog',\n",
              " 253: 'pole vault',\n",
              " 265: 'reading newspaper',\n",
              " 318: 'snatch weight lifting',\n",
              " 399: 'zumba',\n",
              " 235: 'playing ice hockey',\n",
              " 34: 'breakdancing',\n",
              " 124: 'feeding fish',\n",
              " 300: 'shredding paper',\n",
              " 49: 'catching or throwing frisbee',\n",
              " 120: 'exercising with an exercise ball',\n",
              " 262: 'pushing cart',\n",
              " 341: 'swimming butterfly stroke',\n",
              " 274: 'riding scooter',\n",
              " 328: 'spraying',\n",
              " 133: 'folding paper',\n",
              " 142: 'golf driving',\n",
              " 277: 'robot dancing',\n",
              " 20: 'bending back',\n",
              " 354: 'testifying',\n",
              " 387: 'waxing chest',\n",
              " 46: 'carving pumpkin',\n",
              " 153: 'hitting baseball',\n",
              " 269: 'riding elephant',\n",
              " 37: 'brushing teeth',\n",
              " 255: 'pull ups',\n",
              " 267: 'riding a bike',\n",
              " 306: 'skateboarding',\n",
              " 62: 'cleaning pool',\n",
              " 240: 'playing paintball',\n",
              " 193: 'massaging back',\n",
              " 299: 'shoveling snow',\n",
              " 336: 'surfing crowd',\n",
              " 371: 'unboxing',\n",
              " 122: 'faceplanting',\n",
              " 364: 'trapezing',\n",
              " 343: 'swinging legs',\n",
              " 157: 'hoverboarding',\n",
              " 250: 'playing violin',\n",
              " 394: 'wrapping present',\n",
              " 26: 'blowing nose',\n",
              " 174: 'kicking field goal',\n",
              " 214: 'picking fruit',\n",
              " 344: 'swinging on something',\n",
              " 140: 'giving or receiving award',\n",
              " 215: 'planting trees',\n",
              " 383: 'water skiing',\n",
              " 379: 'washing dishes',\n",
              " 258: 'punching bag',\n",
              " 195: 'massaging legs',\n",
              " 356: 'throwing axe',\n",
              " 283: 'salsa dancing',\n",
              " 29: 'bookbinding',\n",
              " 370: 'tying tie',\n",
              " 309: 'skiing crosscountry',\n",
              " 295: 'shining shoes',\n",
              " 189: 'making snowman',\n",
              " 134: 'front raises',\n",
              " 97: 'doing nails',\n",
              " 194: 'massaging feet',\n",
              " 230: 'playing drums',\n",
              " 316: 'smoking',\n",
              " 259: 'punching person (boxing)',\n",
              " 45: 'cartwheeling',\n",
              " 208: 'passing American football (in game)',\n",
              " 288: 'shaking hands',\n",
              " 216: 'plastering',\n",
              " 385: 'watering plants',\n",
              " 176: 'kissing',\n",
              " 314: 'slapping',\n",
              " 233: 'playing harmonica',\n",
              " 391: 'welding',\n",
              " 317: 'smoking hookah',\n",
              " 285: 'scrambling eggs',\n",
              " 70: 'cooking chicken',\n",
              " 261: 'pushing car',\n",
              " 203: 'opening bottle',\n",
              " 73: 'cooking sausages',\n",
              " 48: 'catching or throwing baseball',\n",
              " 340: 'swimming breast stroke',\n",
              " 90: 'digging',\n",
              " 252: 'playing xylophone',\n",
              " 95: 'doing aerobics',\n",
              " 247: 'playing trombone',\n",
              " 178: 'knitting',\n",
              " 377: 'waiting in line',\n",
              " 362: 'tossing salad',\n",
              " 330: 'squat',\n",
              " 376: 'vault',\n",
              " 375: 'using segway',\n",
              " 77: 'crawling baby',\n",
              " 264: 'reading book',\n",
              " 199: 'motorcycling',\n",
              " 14: 'barbequing',\n",
              " 60: 'cleaning floor',\n",
              " 223: 'playing cello',\n",
              " 98: 'drawing',\n",
              " 9: 'auctioning',\n",
              " 44: 'carrying baby',\n",
              " 93: 'diving cliff',\n",
              " 41: 'busking',\n",
              " 83: 'cutting watermelon',\n",
              " 286: 'scuba diving',\n",
              " 270: 'riding mechanical bull',\n",
              " 191: 'making tea',\n",
              " 246: 'playing tennis',\n",
              " 79: 'crying',\n",
              " 107: 'dunking basketball',\n",
              " 76: 'cracking neck',\n",
              " 7: 'arranging flowers',\n",
              " 39: 'building shed',\n",
              " 141: 'golf chipping',\n",
              " 353: 'tasting food',\n",
              " 292: 'shaving head',\n",
              " 2: 'answering questions',\n",
              " 68: 'climbing tree',\n",
              " 311: 'skipping rope',\n",
              " 177: 'kitesurfing',\n",
              " 170: 'juggling fire',\n",
              " 180: 'laughing',\n",
              " 205: 'paragliding',\n",
              " 69: 'contact juggling',\n",
              " 313: 'slacklining',\n",
              " 6: 'arm wrestling',\n",
              " 184: 'making a cake',\n",
              " 127: 'finger snapping',\n",
              " 146: 'grooming horse',\n",
              " 204: 'opening present',\n",
              " 351: 'tapping pen',\n",
              " 304: 'singing',\n",
              " 298: 'shot put',\n",
              " 64: 'cleaning toilet',\n",
              " 326: 'spinning poi',\n",
              " 287: 'setting table',\n",
              " 369: 'tying knot (not on a tie)',\n",
              " 24: 'blowing glass',\n",
              " 112: 'eating chips',\n",
              " 349: 'tap dancing',\n",
              " 66: 'climbing a rope',\n",
              " 35: 'brush painting',\n",
              " 56: 'chopping wood',\n",
              " 334: 'stretching leg',\n",
              " 212: 'petting animal (not cat)',\n",
              " 11: 'baking cookies',\n",
              " 333: 'stretching arm',\n",
              " 16: 'beatboxing',\n",
              " 167: 'jetskiing',\n",
              " 21: 'bending metal',\n",
              " 319: 'sneezing',\n",
              " 131: 'folding clothes',\n",
              " 315: 'sled dog racing',\n",
              " 350: 'tapping guitar',\n",
              " 30: 'bouncing on trampoline',\n",
              " 388: 'waxing eyebrows',\n",
              " 1: 'air drumming',\n",
              " 175: 'kicking soccer ball',\n",
              " 381: 'washing hair',\n",
              " 272: 'riding mule',\n",
              " 25: 'blowing leaves',\n",
              " 335: 'strumming guitar',\n",
              " 222: 'playing cards',\n",
              " 323: 'snowkiting',\n",
              " 221: 'playing bass guitar',\n",
              " 4: 'applying cream',\n",
              " 296: 'shooting basketball',\n",
              " 378: 'walking the dog',\n",
              " 367: 'triple jump',\n",
              " 294: 'shearing sheep',\n",
              " 58: 'clay pottery making',\n",
              " 40: 'bungee jumping',\n",
              " 372: 'unloading truck',\n",
              " 301: 'shuffling cards',\n",
              " 297: 'shooting goal (soccer)',\n",
              " 348: 'tango dancing',\n",
              " 302: 'side kick',\n",
              " 144: 'grinding meat',\n",
              " 398: 'yoga',\n",
              " 148: 'hammer throw',\n",
              " 52: 'changing oil',\n",
              " 54: 'checking tires',\n",
              " 207: 'parkour',\n",
              " 110: 'eating cake',\n",
              " 310: 'skiing slalom',\n",
              " 171: 'juggling soccer ball',\n",
              " 392: 'whistling',\n",
              " 123: 'feeding birds',\n",
              " 251: 'playing volleyball',\n",
              " 342: 'swing dancing',\n",
              " 308: 'skiing (not slalom or crosscountry)',\n",
              " 183: 'lunge',\n",
              " 92: 'disc golfing',\n",
              " 59: 'clean and jerk',\n",
              " 232: 'playing guitar',\n",
              " 10: 'baby waking up',\n",
              " 234: 'playing harp'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3680785",
      "metadata": {
        "id": "a3680785"
      },
      "source": [
        "#### Define input transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d0571e5c",
      "metadata": {
        "id": "d0571e5c"
      },
      "outputs": [],
      "source": [
        "# side_size = 256\n",
        "# mean = [0.45, 0.45, 0.45]\n",
        "# std = [0.225, 0.225, 0.225]\n",
        "# crop_size = 256\n",
        "# num_frames = 50\n",
        "# sampling_rate = 2\n",
        "# frames_per_second = 30\n",
        "# slowfast_alpha = 4\n",
        "# num_clips = 10\n",
        "# num_crops = 3\n",
        "\n",
        "# class PackPathway(torch.nn.Module):\n",
        "#     \"\"\"\n",
        "#     Transform for converting video frames as a list of tensors.\n",
        "#     \"\"\"\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#     def forward(self, frames: torch.Tensor):\n",
        "#         fast_pathway = frames\n",
        "#         # Perform temporal sampling from the fast pathway.\n",
        "#         slow_pathway = torch.index_select(\n",
        "#             frames,\n",
        "#             1,\n",
        "#             torch.linspace(\n",
        "#                 0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
        "#             ).long(),\n",
        "#         )\n",
        "#         frame_list = [slow_pathway, fast_pathway]\n",
        "#         return frame_list\n",
        "\n",
        "# transform =  ApplyTransformToKey(\n",
        "#     key=\"video\",\n",
        "#     transform=Compose(\n",
        "#         [\n",
        "#             UniformTemporalSubsample(num_frames),\n",
        "#             Lambda(lambda x: x/255.0),\n",
        "#             NormalizeVideo(mean, std),\n",
        "#             ShortSideScale(\n",
        "#                 size=side_size\n",
        "#             ),\n",
        "#             CenterCropVideo(crop_size),\n",
        "#             PackPathway()\n",
        "#         ]\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "# # The duration of the input clip is also specific to the model.\n",
        "# clip_duration = (num_frames * sampling_rate)/frames_per_second"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e399b3",
      "metadata": {
        "id": "94e399b3"
      },
      "source": [
        "#### Run Inference\n",
        "\n",
        "Download an example video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e82872",
      "metadata": {
        "id": "93e82872"
      },
      "outputs": [],
      "source": [
        "# url_link = \"https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\"\n",
        "# video_path = 'photograph_ed_sheeran_harshit.mov'\n",
        "# try: urllib.URLopener().retrieve(url_link, video_path)\n",
        "# except: urllib.request.urlretrieve(url_link, video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f5e371",
      "metadata": {
        "id": "b2f5e371"
      },
      "source": [
        "Load the video and transform it to the input format required by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "367aba9a",
      "metadata": {
        "id": "367aba9a"
      },
      "outputs": [],
      "source": [
        "# # Select the duration of the clip to load by specifying the start and end duration\n",
        "# # The start_sec should correspond to where the action occurs in the video\n",
        "# start_sec = 0\n",
        "# end_sec = start_sec + clip_duration\n",
        "# video_path = '/content/piano_trimmed.mp4'\n",
        "\n",
        "# # Initialize an EncodedVideo helper class and load the video\n",
        "# video = EncodedVideo.from_path(video_path)\n",
        "\n",
        "# # Load the desired clip\n",
        "# video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "# # Apply a transform to normalize the video input\n",
        "# video_data = transform(video_data)\n",
        "\n",
        "# # Move the inputs to the desired device\n",
        "# inputs = video_data[\"video\"]\n",
        "# inputs = [i.to(device)[None, ...] for i in inputs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e2afbc",
      "metadata": {
        "id": "22e2afbc"
      },
      "source": [
        "#### Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "06b07aae",
      "metadata": {
        "id": "06b07aae"
      },
      "outputs": [],
      "source": [
        "# # Pass the input clip through the model\n",
        "# preds = model(inputs)\n",
        "\n",
        "# # Get the predicted classes\n",
        "# post_act = torch.nn.Softmax(dim=1)\n",
        "# preds = post_act(preds)\n",
        "# pred_classes = preds.topk(k=5).indices[0]\n",
        "\n",
        "# # Map the predicted classes to the label names\n",
        "# pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]\n",
        "# print(\"Top 5 predicted labels: %s\" % \", \".join(pred_class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86f5f2ef",
      "metadata": {
        "id": "86f5f2ef"
      },
      "source": [
        "### Model Description\n",
        "SlowFast model architectures are based on [1] with pretrained weights using the 8x8 setting\n",
        "on the Kinetics dataset.\n",
        "\n",
        "| arch | depth | frame length x sample rate | top 1 | top 5 | Flops (G) | Params (M) |\n",
        "| --------------- | ----------- | ----------- | ----------- | ----------- | ----------- |  ----------- |\n",
        "| SlowFast | R50   | 8x8                        | 76.94 | 92.69 | 65.71     | 34.57      |\n",
        "| SlowFast | R101  | 8x8                        | 77.90 | 93.27 | 127.20    | 62.83      |\n",
        "\n",
        "\n",
        "### References\n",
        "[1] Christoph Feichtenhofer et al, \"SlowFast Networks for Video Recognition\"\n",
        "https://arxiv.org/pdf/1812.03982.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input transform modifications for custom video (e.g. my piano video where height > width)\n",
        "\n",
        "* The aspect ratio is preserved during resizing.\n",
        "* The frames are correctly centered and cropped.\n",
        "* The pixel values are normalized correctly.\n",
        "* The frames are sampled properly for the SlowFast model's pathways."
      ],
      "metadata": {
        "id": "ThusLzgoitsN"
      },
      "id": "ThusLzgoitsN"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "from typing import Any, List, Dict"
      ],
      "metadata": {
        "id": "nFTRGI5tgb9j"
      },
      "id": "nFTRGI5tgb9j",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_short_side(size: int, frame: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Scale the short side of the frame to size and return a float\n",
        "    array.\n",
        "    \"\"\"\n",
        "    height = frame.shape[0]\n",
        "    width = frame.shape[1]\n",
        "    # return unchanged if short side already scaled\n",
        "    if (width <= height and width == size) or (height <= width and height == size):\n",
        "        return frame\n",
        "    new_width = size\n",
        "    new_height = size\n",
        "    if width < height:\n",
        "        new_height = int(math.floor((float(height) / width) * size))\n",
        "    else:\n",
        "        new_width = int(math.floor((float(width) / height) * size))\n",
        "    scaled = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
        "    return scaled.astype(np.float32)\n",
        "\n",
        "\n",
        "def center_crop(size: int, frame: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Center crop the input frame to size.\n",
        "    \"\"\"\n",
        "    height = frame.shape[0]\n",
        "    width = frame.shape[1]\n",
        "    y_offset = int(math.ceil((height - size) / 2))\n",
        "    x_offset = int(math.ceil((width - size) / 2))\n",
        "    cropped = frame[y_offset:y_offset + size, x_offset:x_offset + size, :]\n",
        "    assert cropped.shape[0] == size, \"Image height not cropped properly\"\n",
        "    assert cropped.shape[1] == size, \"Image width not cropped properly\"\n",
        "    return cropped\n",
        "\n",
        "\n",
        "def normalize(array: np.ndarray, mean: List[float], std: List[float]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalize a given array by subtracting the mean and dividing the std.\n",
        "    \"\"\"\n",
        "    if array.dtype == np.uint8:\n",
        "        array = array.astype(np.float32)\n",
        "        array = array / 255.0\n",
        "    mean = np.array(mean, dtype=np.float32)\n",
        "    std = np.array(std, dtype=np.float32)\n",
        "    array = array - mean\n",
        "    array = array / std\n",
        "    return array\n",
        "\n",
        "\n",
        "def pack_pathway_output(frames: np.ndarray, alpha: int = 4) -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Prepare output as a list of arrays, each corresponding\n",
        "    to a unique pathway.\n",
        "    \"\"\"\n",
        "    fast_pathway = frames\n",
        "    # Perform temporal sampling from the fast pathway.\n",
        "    slow_pathway = np.take(\n",
        "        frames,\n",
        "        indices=np.linspace(0, frames.shape[1] - 1, frames.shape[1] // alpha).astype(np.int_),\n",
        "        axis=1\n",
        "    )\n",
        "    frame_list = [slow_pathway, fast_pathway]\n",
        "    return frame_list\n",
        "\n",
        "\n",
        "def process_inputs(\n",
        "    frames: List[np.ndarray],\n",
        "    num_frames: int,\n",
        "    crop_size: int,\n",
        "    mean: List[float],\n",
        "    std: List[float],\n",
        ") -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Performs normalization and applies required transforms\n",
        "    to prepare the input frames and returns a list of arrays.\n",
        "    Specifically the following actions are performed\n",
        "    1. scale the short side of the frames\n",
        "    2. center crop the frames to crop_size\n",
        "    3. perform normalization by subtracting mean and dividing std\n",
        "    4. sample frames for specified num_frames\n",
        "    5. sample frames for slow and fast pathways\n",
        "    \"\"\"\n",
        "    inputs = [scale_short_side(size=crop_size, frame=frame) for frame in frames]\n",
        "    inputs = [center_crop(size=crop_size, frame=frame) for frame in inputs]\n",
        "    inputs = np.array(inputs).astype(np.float32) / 255\n",
        "    inputs = normalize(array=inputs, mean=mean, std=std)\n",
        "    # T H W C -> C T H W\n",
        "    inputs = inputs.transpose([3, 0, 1, 2])\n",
        "    # Sample frames for num_frames specified\n",
        "    indices = np.linspace(0, inputs.shape[1] - 1, num_frames).astype(np.int_)\n",
        "    inputs = np.take(inputs, indices=indices, axis=1)\n",
        "    # prepare pathways for the model\n",
        "    inputs = pack_pathway_output(inputs)\n",
        "    inputs = [np.expand_dims(inp, 0) for inp in inputs]\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "xn8Gu6UIBBzJ"
      },
      "id": "xn8Gu6UIBBzJ",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(\n",
        "    model: Any,\n",
        "    video_path: str,\n",
        "    top_k: int,\n",
        "    id_to_label_mapping: Dict[str, str],\n",
        "    num_frames: int,\n",
        "    sampling_rate: int,\n",
        "    crop_size: int,\n",
        "    mean: List[float],\n",
        "    std: List[float],\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Run inference on the video given by video_path using the given model.\n",
        "    First, the video is loaded from source. Frames are collected, processed\n",
        "    and fed to the model. The top top_k predicted class IDs are converted to class\n",
        "    labels and returned as a list of strings.\n",
        "    \"\"\"\n",
        "    video_cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    seq_length = num_frames * sampling_rate\n",
        "    # get the list of frames from the video\n",
        "    ret = True\n",
        "    while ret and len(frames) < seq_length:\n",
        "        ret, frame = video_cap.read()\n",
        "        frames.append(frame)\n",
        "    # prepare the inputs\n",
        "    inputs = process_inputs(\n",
        "        frames=frames, num_frames=num_frames, crop_size=crop_size, mean=mean, std=std\n",
        "    )\n",
        "\n",
        "\n",
        "    # pytorch model\n",
        "    predictions = model([torch.from_numpy(inp).to('cuda') for inp in inputs])\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "    def softmax(x):\n",
        "        return (np.exp(x) / np.exp(x).sum(axis=None))\n",
        "\n",
        "    # apply activation\n",
        "    predictions = softmax(predictions)\n",
        "\n",
        "    # top k predicted class IDs\n",
        "    topk = 5\n",
        "    pred_classes = np.argsort(-1 * predictions, axis=1)[:, :topk]\n",
        "\n",
        "    # Map the predicted classes to the label names\n",
        "    pred_class_names = [id_to_label_mapping[int(i)] for i in pred_classes[0]]\n",
        "    return pred_class_names"
      ],
      "metadata": {
        "id": "g94vKXp3gawx"
      },
      "id": "g94vKXp3gawx",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FRAMES = 32\n",
        "SAMPLING_RATE = 2\n",
        "CROP_SIZE = 256\n",
        "MEAN = [0.45, 0.45, 0.45]\n",
        "STD = [0.225, 0.225, 0.225]\n",
        "TOP_K = 5\n",
        "\n",
        "predictions = run_inference(\n",
        "    model=model,\n",
        "    video_path=str('/content/piano_trimmed.mp4'),\n",
        "    top_k=TOP_K,\n",
        "    id_to_label_mapping=kinetics_id_to_classname,\n",
        "    num_frames=NUM_FRAMES,\n",
        "    sampling_rate=SAMPLING_RATE,\n",
        "    crop_size=CROP_SIZE,\n",
        "    mean=MEAN,\n",
        "    std=STD,\n",
        ")\n",
        "\n",
        "print(f\"Predicted labels: {', '.join(predictions)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-_SSLgggrKq",
        "outputId": "d056742b-c75f-48b2-93be-af5e67fea083"
      },
      "id": "d-_SSLgggrKq",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: playing keyboard, playing organ, playing xylophone, playing piano, playing flute\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:605: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv3d(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is **playing keyboard** as expected!"
      ],
      "metadata": {
        "id": "PUa1tfaAjExI"
      },
      "id": "PUa1tfaAjExI"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQLbge48guai"
      },
      "id": "ZQLbge48guai",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}